{
  "operationMode": "TRAIN_SPLITTED_ONLY",
  "splitParams": {
    "ttPolicy": "SPLIT_SINGLE_DATASET",
    "ssdSplitMode": "RANDOM",
    "splitBeforePrepare": true,
    "ssdSelection": {
      "useMemTable": false,
      "filter": {
        "distinct": false,
        "enabled": false
      },
      "partitionSelectionMethod": "ALL",
      "latestPartitionsN": 1,
      "ordering": {
        "enabled": false,
        "rules": []
      },
      "samplingMethod": "HEAD_SEQUENTIAL",
      "maxRecords": 100000,
      "targetRatio": 0.02,
      "withinFirstN": -1,
      "maxReadUncompressedBytes": -1
    },
    "ssdTrainingRatio": 0.8,
    "ssdSeed": 1337,
    "testOnLargerValues": true,
    "kfold": false,
    "nFolds": 5,
    "instanceIdRefresher": 0,
    "subSamplingSeed": 1337
  },
  "backendType": "KERAS",
  "sparkParams": {
    "sparkConf": {
      "inheritConf": "default",
      "conf": []
    },
    "sparkUseGlobalMetastore": false,
    "sparkPreparedDFStorageLevel": "MEMORY_AND_DISK",
    "sparkRepartitionNonHDFS": 1,
    "pipelineAllowStart": true,
    "pipelineAllowMerge": true,
    "sparkExecutionEngine": "SPARK_SUBMIT"
  },
  "envName": "dl_nlp",
  "envSelection": {
    "envMode": "EXPLICIT_ENV",
    "envName": "dl_nlp"
  },
  "script": {
    "steps": [],
    "maxProcessedMemTableBytes": -1,
    "contextProjectKey": "IMDBMOVIEREVIEWSNLP",
    "columnsSelection": {
      "mode": "ALL"
    },
    "columnWidthsByName": {},
    "coloring": {
      "scheme": "MEANING_AND_STATUS",
      "individualColumns": [],
      "valueColoringMode": "HASH"
    },
    "sorting": [],
    "analysisColumnData": {},
    "explorationSampling": {
      "selection": {
        "maxStoredBytes": 104857600,
        "filter": {
          "distinct": false,
          "enabled": false
        },
        "partitionSelectionMethod": "ALL",
        "latestPartitionsN": 1,
        "ordering": {
          "enabled": false,
          "rules": []
        },
        "samplingMethod": "HEAD_SEQUENTIAL",
        "maxRecords": 10000,
        "targetRatio": 0.02,
        "withinFirstN": -1,
        "maxReadUncompressedBytes": -1
      },
      "autoRefreshSample": false,
      "_refreshTrigger": 0
    },
    "vizSampling": {
      "autoRefreshSample": false,
      "_refreshTrigger": 0
    },
    "exploreUIParams": {},
    "globalSearchQuery": "",
    "explorationFilters": [],
    "previewMode": "ALL_ROWS"
  },
  "expectedPreparationOutputSchema": {
    "columns": [
      {"name":"text","type":"string"},
      {"name":"sentiment","type":"bigint"},
      {"name":"polarity","type":"bigint"},
      {"name":"sample","type":"string"},
      {"name":"text_clean","type":"string"}
    ],
    "userModified": false
  },
  "core": {
    "target_variable": "polarity",
    "prediction_type": "BINARY_CLASSIFICATION",
    "weight": {
      "weightMethod": "NO_WEIGHTING"
    },
    "calibration": {
      "calibrationMethod": "NO_CALIBRATION"
    },
    "time": {
      "enabled": false,
      "ascending": true
    },
    "partitionedModel": {
      "enabled": false,
      "ssdSelection": {
        "useMemTable": false,
        "filter": {
          "distinct": false,
          "enabled": false
        },
        "partitionSelectionMethod": "ALL",
        "latestPartitionsN": 1,
        "ordering": {
          "enabled": false,
          "rules": []
        },
        "samplingMethod": "FULL",
        "maxRecords": -1,
        "targetRatio": 0.02,
        "withinFirstN": -1,
        "maxReadUncompressedBytes": -1
      }
    },
    "backendType": "KERAS",
    "taskType": "PREDICTION",
    "executionParams": {
      "envSelection": {
        "envMode": "EXPLICIT_ENV",
        "envName": "dl_nlp"
      },
      "envName": "dl_nlp",
      "containerSelection": {
        "containerMode": "INHERIT"
      },
      "sparkParams": {
        "sparkConf": {
          "inheritConf": "default",
          "conf": []
        },
        "sparkUseGlobalMetastore": false,
        "sparkPreparedDFStorageLevel": "MEMORY_AND_DISK",
        "sparkRepartitionNonHDFS": 1,
        "pipelineAllowStart": true,
        "pipelineAllowMerge": true,
        "sparkExecutionEngine": "SPARK_SUBMIT"
      },
      "sparkCheckpoint": "NONE"
    }
  },
  "preprocessing": {
    "target_remapping": [
      {
        "sourceValue": "0",
        "mappedValue": 0,
        "sampleFreq": 5040
      },
      {
        "sourceValue": "1",
        "mappedValue": 1,
        "sampleFreq": 4960
      }
    ],
    "skipPreprocessing": false,
    "per_feature": {
      "sentiment": {
        "generate_derivative": false,
        "numerical_handling": "REGULAR",
        "missing_handling": "IMPUTE",
        "missing_impute_with": "MEAN",
        "impute_constant_value": 0.0,
        "rescaling": "AVGSTD",
        "quantile_bin_nb_bins": 4,
        "binarize_threshold_mode": "MEDIAN",
        "binarize_constant_threshold": 0.0,
        "role": "REJECT",
        "type": "NUMERIC",
        "state": {
          "userModified": false,
          "autoModifiedByDSS": false,
          "recordedMeaning": "LongMeaning"
        },
        "customHandlingCode": "",
        "customProcessorWantsMatrix": false,
        "sendToInput": "main"
      },
      "text": {
        "text_handling": "CUSTOM",
        "minRowsRatio": 0.001,
        "maxRowsRatio": 0.8,
        "maxWords": 0,
        "ngramMinSize": 1,
        "ngramMaxSize": 1,
        "hashSVDHashSize": 200000,
        "hashSVDSVDLimit": 50000,
        "hashSVDSVDComponents": 100,
        "stopWordsMode": "NONE",
        "useCustomVectorizer": false,
        "name": "text",
        "role": "REJECT",
        "type": "TEXT",
        "state": {
          "userModified": false,
          "autoModifiedByDSS": false,
          "recordedMeaning": "FreeText"
        },
        "customHandlingCode": "from dataiku.doctor.deep_learning.preprocessing import TokenizerProcessor\n\n# Defines a processor that tokenizes a text. It computes a vocabulary on all the corpus.\n# Then, each text is converted to a vector representing the sequence of words, where each \n# element represents the index of the corresponding word in the vocabulary. The result is \n# padded with 0 up to the `max_len` in order for all the vectors to have the same length.\n\n#   num_words  - maximum number of words in the vocabulary\n#   max_len    - length of each sequence. If the text is longer,\n#                it will be truncated, and if it is shorter, it will be padded\n#                with 0.\nprocessor \u003d TokenizerProcessor(num_words\u003d10000, max_len\u003d32)",
        "customProcessorWantsMatrix": false,
        "sendToInput": "main"
      },
      "sample": {
        "category_handling": "DUMMIFY",
        "missing_handling": "NONE",
        "missing_impute_with": "MODE",
        "dummy_clip": "MAX_NB_CATEGORIES",
        "cumulative_proportion": 0.95,
        "min_samples": 10,
        "max_nb_categories": 100,
        "max_cat_safety": 200,
        "dummy_drop": "NONE",
        "role": "REJECT",
        "type": "CATEGORY",
        "state": {
          "userModified": false,
          "autoModifiedByDSS": false,
          "recordedMeaning": "Text"
        },
        "autoReason": "REJECT_ZERO_VARIANCE",
        "customHandlingCode": "",
        "customProcessorWantsMatrix": false,
        "sendToInput": "main"
      },
      "text_clean": {
        "text_handling": "CUSTOM",
        "minRowsRatio": 0.001,
        "maxRowsRatio": 0.8,
        "maxWords": 0,
        "ngramMinSize": 1,
        "ngramMaxSize": 1,
        "hashSVDHashSize": 200000,
        "hashSVDSVDLimit": 50000,
        "hashSVDSVDComponents": 100,
        "stopWordsMode": "NONE",
        "useCustomVectorizer": false,
        "name": "text_clean",
        "role": "INPUT",
        "type": "TEXT",
        "state": {
          "userModified": true,
          "autoModifiedByDSS": false,
          "recordedMeaning": "FreeText"
        },
        "customHandlingCode": "from dataiku.doctor.deep_learning.preprocessing import TokenizerProcessor\n\n# Defines a processor that tokenizes a text. It computes a vocabulary on all the corpus.\n# Then, each text is converted to a vector representing the sequence of words, where each \n# element represents the index of the corresponding word in the vocabulary. The result is \n# padded with 0 up to the `max_len` in order for all the vectors to have the same length.\n\n#   num_words  - maximum number of words in the vocabulary\n#   max_len    - length of each sequence. If the text is longer,\n#                it will be truncated, and if it is shorter, it will be padded\n#                with 0.\nprocessor \u003d TokenizerProcessor(num_words\u003d10000, max_len\u003d500)",
        "customProcessorWantsMatrix": false,
        "sendToInput": "text_clean_preprocessed"
      },
      "polarity": {
        "generate_derivative": false,
        "impute_constant_value": 0.0,
        "quantile_bin_nb_bins": 4,
        "binarize_threshold_mode": "MEDIAN",
        "binarize_constant_threshold": 0.0,
        "role": "TARGET",
        "type": "NUMERIC",
        "state": {
          "userModified": false,
          "autoModifiedByDSS": false,
          "recordedMeaning": "LongMeaning"
        },
        "customHandlingCode": "",
        "customProcessorWantsMatrix": false,
        "sendToInput": "main"
      }
    },
    "reduce": {
      "enabled": false,
      "kept_variance": 0.0
    },
    "feature_generation": {
      "pairwise_linear": {
        "behavior": "DISABLED"
      },
      "polynomial_combinations": {
        "behavior": "DISABLED"
      },
      "manual_interactions": {
        "interactions": []
      },
      "numericals_clustering": {
        "k": 0,
        "all_features": false,
        "input_features": [],
        "behavior": "DISABLED"
      },
      "categoricals_count_transformer": {
        "all_features": false,
        "input_features": [],
        "behavior": "DISABLED"
      }
    },
    "feature_selection_params": {
      "method": "NONE",
      "random_forest_params": {
        "n_trees": 30,
        "depth": 10,
        "n_features": 25
      },
      "lasso_params": {
        "alpha": [
          0.01,
          0.1,
          1.0,
          10.0,
          100.0
        ],
        "cross_validate": true
      },
      "pca_params": {
        "n_features": 25,
        "variance_proportion": 0.9
      },
      "correlation_params": {
        "min_abs_correlation": 0.0,
        "n_features": 25
      },
      "custom_params": {
        "code": "# type your code here"
      }
    },
    "preprocessingFitSampleRatio": 1.0,
    "preprocessingFitSampleSeed": 1337
  },
  "modeling": {
    "algorithm": "KERAS_CODE",
    "keras": {
      "epochs": 2,
      "batchSize": 32,
      "trainOnAllData": true,
      "stepsPerEpoch": 100,
      "shuffleData": true,
      "useGPU": false,
      "gpuList": [
        0
      ],
      "perGPUMemoryFraction": 0.5,
      "gpuAllowGrowth": false,
      "advancedFitMode": false,
      "enabled": true,
      "kerasInputs": [
        "main",
        "text_clean_preprocessed"
      ],
      "buildCode": "from keras.layers import Embedding, LSTM\nfrom keras.layers import Dense, Input, Flatten\nfrom keras.models import Model\n\ndef build_model(input_shapes, n_classes\u003dNone):\n\n    #### DEFINING THE INPUT\n    # You need to modify the name and length of the \"text_input\" \n    # according to the preprocessing and name of your \n    # initial feature.\n    # This feature should to be preprocessed as a \"Text\", with a \n    # custom preprocessing using the \"TokenizerProcessor\" class\n    text_length \u003d 500\n    vocabulary_size \u003d 10000\n    text_input_name \u003d \"text_clean_preprocessed\"\n\n    text_input \u003d Input(shape\u003d(text_length,), name\u003dtext_input_name)\n\n    #### DEFINING THE ARCHITECTURE\n    emb \u003d Embedding(output_dim\u003d512, input_dim\u003dvocabulary_size, input_length\u003dtext_length)(text_input)\n    lstm_out \u003d LSTM(128)(emb)\n    \n    x \u003d Dense(128, activation\u003d\u0027relu\u0027)(lstm_out)\n    x \u003d Dense(64, activation\u003d\u0027relu\u0027)(x)\n    predictions \u003d Dense(n_classes, activation\u003d\u0027softmax\u0027)(x)\n\n    model \u003d Model(inputs\u003dtext_input, outputs\u003dpredictions)\n\n    return model\n\ndef compile_model(model):\n    model.compile(\n        optimizer\u003d\"rmsprop\",\n        loss\u003d\"categorical_crossentropy\"\n    )\n    return model\n\n"
    },
    "max_ensemble_nodes_serialized": 0,
    "metrics": {
      "evaluationMetric": "ROC_AUC",
      "customEvaluationMetricGIB": true,
      "customEvaluationMetricNeedsProba": false,
      "thresholdOptimizationMetric": "F1",
      "costMatrixWeights": {
        "tpGain": 1.0,
        "tnGain": 0.0,
        "fpGain": -0.3,
        "fnGain": 0.0
      },
      "liftPoint": 0.4
    },
    "autoOptimizeThreshold": true,
    "forcedClassifierThreshold": 0.0,
    "gridLength": 2,
    "grid_search_params": {
      "mode": "KFOLD",
      "splitRatio": 0.8,
      "shuffleIterations": 1,
      "nFolds": 3,
      "stratified": true,
      "strategy": "GRID",
      "randomized": true,
      "nIter": 0,
      "timeout": 0,
      "nJobs": 4
    },
    "pluginAlgoCustomGridSearch": false,
    "computeLearningCurves": false,
    "skipExpensiveReports": false
  },
  "partSource": "ACTIVE_VERSION",
  "generatingModelId": "A-IMDBMOVIEREVIEWSNLP-jUMSRe7D-df8xUSYb-s4-pp1-m1"
}